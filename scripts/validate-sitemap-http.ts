/**
 * é€šè¿‡ HTTP è¯·æ±‚éªŒè¯å®é™… sitemap ä¸­çš„ URL
 * 
 * åŠŸèƒ½ï¼š
 * 1. è·å–ä¸» sitemap.xml
 * 2. è§£ææ‰€æœ‰å­ sitemap
 * 3. æå–æ‰€æœ‰ URL
 * 4. æ£€æŸ¥æ¯ä¸ª URL æ˜¯å¦å¯è®¿é—®
 * 5. éªŒè¯ URL æ˜¯å¦åœ¨æ•°æ®åº“ä¸­å­˜åœ¨
 * 6. ç”ŸæˆéªŒè¯æŠ¥å‘Š
 * 
 * ä½¿ç”¨æ–¹æ³•:
 *   npx tsx scripts/validate-sitemap-http.ts [--base-url=https://sora2aivideos.com]
 * 
 * å¯é€‰å‚æ•°:
 *   --base-url: ç½‘ç«™åŸºç¡€ URLï¼ˆé»˜è®¤: https://sora2aivideos.comï¼‰
 *   --export-csv: å¯¼å‡ºç»“æœåˆ° CSV æ–‡ä»¶
 *   --check-http: æ£€æŸ¥ URL çš„ HTTP çŠ¶æ€ç ï¼ˆè¾ƒæ…¢ï¼‰
 */

import { config } from 'dotenv'
import { resolve } from 'path'
import { writeFileSync } from 'fs'
import { createClient } from '@supabase/supabase-js'
import type { Database } from '@/types/database'

// Load environment variables
config({ path: resolve(process.cwd(), '.env.local') })

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY
let baseUrl = process.env.NEXT_PUBLIC_SITE_URL || 'https://sora2aivideos.com'

// Parse command line arguments
const args = process.argv.slice(2)
const exportCsv = args.includes('--export-csv')
const checkHttp = args.includes('--check-http')

const baseUrlArg = args.find((arg) => arg.startsWith('--base-url='))
if (baseUrlArg) {
  baseUrl = baseUrlArg.split('=')[1]
}

if (!supabaseUrl || !supabaseServiceKey) {
  console.error('âŒ ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡')
  process.exit(1)
}

const supabase = createClient<Database>(supabaseUrl, supabaseServiceKey)

interface SitemapURL {
  url: string
  sitemap: string
  existsInDatabase: boolean
  published: boolean
  httpStatus?: number
  httpError?: string
  databaseId?: number | string
  type: 'use-case' | 'keyword' | 'blog' | 'prompt' | 'compare' | 'industry' | 'static' | 'unknown'
  slug: string | null
}

/**
 * è§£æ URL å¹¶è¯†åˆ«ç±»å‹
 */
function parseURL(url: string): { type: SitemapURL['type']; slug: string | null } {
  try {
    const urlObj = new URL(url)
    const path = urlObj.pathname

    if (path.startsWith('/use-cases/')) {
      const slug = path.replace('/use-cases/', '').split('?')[0]
      return { type: 'use-case', slug: slug || null }
    }
    if (path.startsWith('/keywords/')) {
      const slug = path.replace('/keywords/', '').split('?')[0]
      return { type: 'keyword', slug: slug || null }
    }
    if (path.startsWith('/blog/') && path !== '/blog') {
      const slug = path.replace('/blog/', '').split('?')[0]
      return { type: 'blog', slug: slug || null }
    }
    if (path.startsWith('/prompts/')) {
      const slug = path.replace('/prompts/', '').split('?')[0]
      return { type: 'prompt', slug: slug || null }
    }
    if (path.startsWith('/compare/') && path !== '/compare') {
      const slug = path.replace('/compare/', '').split('?')[0]
      return { type: 'compare', slug: slug || null }
    }
    if (path.startsWith('/industries/')) {
      const slug = path.replace('/industries/', '').split('?')[0]
      return { type: 'industry', slug: slug || null }
    }

    const staticPaths = ['/', '/video', '/blog', '/prompts', '/compare', '/support', '/privacy', '/terms']
    if (staticPaths.includes(path)) {
      return { type: 'static', slug: null }
    }

    return { type: 'unknown', slug: null }
  } catch {
    return { type: 'unknown', slug: null }
  }
}

/**
 * è·å– sitemap XML
 */
async function fetchSitemap(url: string): Promise<string> {
  try {
    const response = await fetch(url, {
      headers: {
        'User-Agent': 'Mozilla/5.0 (compatible; SitemapValidator/1.0)',
      },
    })
    
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`)
    }
    
    return await response.text()
  } catch (error) {
    throw new Error(`è·å– sitemap å¤±è´¥: ${error instanceof Error ? error.message : String(error)}`)
  }
}

/**
 * è§£æ sitemap XML å¹¶æå– URL
 */
function extractURLsFromSitemap(xml: string): string[] {
  const urls: string[] = []
  
  // æå– <loc> æ ‡ç­¾ä¸­çš„ URL
  const locRegex = /<loc>(.*?)<\/loc>/g
  let match
  while ((match = locRegex.exec(xml)) !== null) {
    const url = match[1].trim()
    if (url) {
      urls.push(url)
    }
  }
  
  return urls
}

/**
 * è§£æ sitemap index å¹¶æå–å­ sitemap URL
 */
function extractSitemapIndex(xml: string): string[] {
  const sitemaps: string[] = []
  
  // æå– <sitemap><loc> ä¸­çš„ URL
  const sitemapRegex = /<sitemap>\s*<loc>(.*?)<\/loc>/g
  let match
  while ((match = sitemapRegex.exec(xml)) !== null) {
    const url = match[1].trim()
    if (url) {
      sitemaps.push(url)
    }
  }
  
  return sitemaps
}

/**
 * æ£€æŸ¥ URL æ˜¯å¦åœ¨æ•°æ®åº“ä¸­å­˜åœ¨
 */
async function checkURLInDatabase(url: SitemapURL): Promise<SitemapURL> {
  if (!url.slug || url.type === 'unknown' || url.type === 'static') {
    url.existsInDatabase = true // é™æ€é¡µé¢æ€»æ˜¯å­˜åœ¨
    url.published = true
    return url
  }

  try {
    switch (url.type) {
      case 'use-case': {
        const { data } = await supabase
          .from('use_cases')
          .select('id, is_published')
          .eq('slug', decodeURIComponent(url.slug))
          .maybeSingle()
        
        if (data) {
          const useCase = data as { id: number; is_published: boolean }
          url.existsInDatabase = true
          url.published = useCase.is_published
          url.databaseId = useCase.id
        } else {
          url.existsInDatabase = false
        }
        break
      }

      case 'keyword': {
        const { data } = await supabase
          .from('long_tail_keywords')
          .select('id, status')
          .eq('page_slug', decodeURIComponent(url.slug))
          .maybeSingle()
        
        if (data) {
          const keyword = data as { id: number; status: string }
          url.existsInDatabase = true
          url.published = keyword.status === 'published'
          url.databaseId = keyword.id
        } else {
          url.existsInDatabase = false
        }
        break
      }

      case 'blog': {
        const { data } = await supabase
          .from('blog_posts')
          .select('id, is_published')
          .eq('slug', decodeURIComponent(url.slug))
          .maybeSingle()
        
        if (data) {
          const blogPost = data as { id: number; is_published: boolean }
          url.existsInDatabase = true
          url.published = blogPost.is_published
          url.databaseId = blogPost.id
        } else {
          url.existsInDatabase = false
        }
        break
      }

      case 'prompt': {
        const { data } = await supabase
          .from('prompt_library')
          .select('id, is_published')
          .eq('slug', decodeURIComponent(url.slug))
          .maybeSingle()
        
        if (data) {
          const prompt = data as { id: number; is_published: boolean }
          url.existsInDatabase = true
          url.published = prompt.is_published
          url.databaseId = prompt.id
        } else {
          url.existsInDatabase = false
        }
        break
      }

      case 'compare': {
        const { data } = await supabase
          .from('compare_pages')
          .select('id, is_published')
          .eq('slug', decodeURIComponent(url.slug))
          .maybeSingle()
        
        if (data) {
          const comparePage = data as { id: number; is_published: boolean }
          url.existsInDatabase = true
          url.published = comparePage.is_published
          url.databaseId = comparePage.id
        } else {
          url.existsInDatabase = false
        }
        break
      }

      case 'industry': {
        url.existsInDatabase = true
        url.published = true
        break
      }
    }
  } catch (error) {
    url.httpError = `æ•°æ®åº“æŸ¥è¯¢é”™è¯¯: ${error instanceof Error ? error.message : String(error)}`
  }

  return url
}

/**
 * æ£€æŸ¥ URL çš„ HTTP çŠ¶æ€ç 
 */
async function checkHTTPStatus(url: SitemapURL): Promise<SitemapURL> {
  try {
    const response = await fetch(url.url, {
      method: 'HEAD',
      headers: {
        'User-Agent': 'Mozilla/5.0 (compatible; SitemapValidator/1.0)',
      },
      redirect: 'follow',
    })
    
    url.httpStatus = response.status
  } catch (error) {
    url.httpError = error instanceof Error ? error.message : String(error)
  }

  return url
}

/**
 * ä¸»å‡½æ•°
 */
async function main() {
  console.log('ğŸš€ å¼€å§‹éªŒè¯ sitemap ä¸­çš„ URL...\n')
  console.log(`Base URL: ${baseUrl}\n`)
  console.log('='.repeat(60) + '\n')

  // 1. è·å–ä¸» sitemap
  console.log('ğŸ“‹ è·å–ä¸» sitemap...')
  const mainSitemapUrl = `${baseUrl}/sitemap.xml`
  let mainSitemapXML: string
  
  try {
    mainSitemapXML = await fetchSitemap(mainSitemapUrl)
    console.log('âœ… æˆåŠŸè·å–ä¸» sitemap\n')
  } catch (error) {
    console.error('âŒ è·å–ä¸» sitemap å¤±è´¥:', error)
    console.error('æç¤º: ç¡®ä¿ç½‘ç«™æ­£åœ¨è¿è¡Œæˆ–ä½¿ç”¨ --base-url å‚æ•°æŒ‡å®šæ­£ç¡®çš„ URL')
    process.exit(1)
  }

  // 2. è§£æ sitemap index
  const sitemapUrls = extractSitemapIndex(mainSitemapXML)
  console.log(`ğŸ“‹ æ‰¾åˆ° ${sitemapUrls.length} ä¸ªå­ sitemap\n`)

  // 3. è·å–æ‰€æœ‰å­ sitemap çš„ URL
  const allURLs: SitemapURL[] = []
  
  for (let i = 0; i < sitemapUrls.length; i++) {
    const sitemapUrl = sitemapUrls[i]
    console.log(`[${i + 1}/${sitemapUrls.length}] å¤„ç†: ${sitemapUrl}`)
    
    try {
      const sitemapXML = await fetchSitemap(sitemapUrl)
      const urls = extractURLsFromSitemap(sitemapXML)
      console.log(`  âœ… æ‰¾åˆ° ${urls.length} ä¸ª URL`)
      
      urls.forEach((url) => {
        const parsed = parseURL(url)
        allURLs.push({
          url,
          sitemap: sitemapUrl,
          existsInDatabase: false,
          published: false,
          type: parsed.type,
          slug: parsed.slug,
        })
      })
    } catch (error) {
      console.error(`  âŒ å¤„ç†å¤±è´¥: ${error instanceof Error ? error.message : String(error)}`)
    }
  }

  console.log(`\nğŸ“Š æ€»å…±æ‰¾åˆ° ${allURLs.length} ä¸ª URL\n`)
  console.log('='.repeat(60) + '\n')

  // 4. éªŒè¯æ¯ä¸ª URL
  console.log('ğŸ” éªŒè¯ URL...\n')
  
  for (let i = 0; i < allURLs.length; i++) {
    const url = allURLs[i]
    if ((i + 1) % 100 === 0) {
      console.log(`[${i + 1}/${allURLs.length}] éªŒè¯ä¸­...`)
    }
    
    await checkURLInDatabase(url)
    
    if (checkHttp) {
      await checkHTTPStatus(url)
    }
  }

  // 5. ç”ŸæˆæŠ¥å‘Š
  console.log('\n' + '='.repeat(60))
  console.log('ğŸ“Š éªŒè¯æ‘˜è¦')
  console.log('='.repeat(60))

  const existsCount = allURLs.filter((u) => u.existsInDatabase).length
  const notExistsCount = allURLs.filter((u) => !u.existsInDatabase).length
  const unpublishedCount = allURLs.filter((u) => u.existsInDatabase && !u.published).length
  const httpErrorCount = checkHttp ? allURLs.filter((u) => u.httpStatus && u.httpStatus >= 400).length : 0

  console.log(`æ€» URL æ•°: ${allURLs.length}`)
  console.log(`âœ… å­˜åœ¨äºæ•°æ®åº“: ${existsCount}`)
  console.log(`âŒ ä¸å­˜åœ¨äºæ•°æ®åº“: ${notExistsCount}`)
  if (checkHttp) {
    console.log(`âš ï¸  HTTP é”™è¯¯ (>=400): ${httpErrorCount}`)
  }
  console.log(`âš ï¸  å­˜åœ¨ä½†æœªå‘å¸ƒ: ${unpublishedCount}`)

  // æŒ‰ç±»å‹ç»Ÿè®¡
  console.log('\næŒ‰ç±»å‹ç»Ÿè®¡:')
  const typeStats = allURLs.reduce((acc, u) => {
    acc[u.type] = (acc[u.type] || 0) + 1
    return acc
  }, {} as Record<string, number>)

  Object.entries(typeStats).forEach(([type, count]) => {
    const exists = allURLs.filter((u) => u.type === type && u.existsInDatabase).length
    console.log(`  ${type}: ${count} (å­˜åœ¨: ${exists}, ä¸å­˜åœ¨: ${count - exists})`)
  })

  // æ˜¾ç¤ºé—®é¢˜ URL
  const problemURLs = allURLs.filter((u) => !u.existsInDatabase || (checkHttp && u.httpStatus && u.httpStatus >= 400))
  if (problemURLs.length > 0) {
    console.log(`\nâš ï¸  å‘ç° ${problemURLs.length} ä¸ªé—®é¢˜ URL:`)
    problemURLs.slice(0, 10).forEach((u) => {
      console.log(`  - ${u.url}`)
      if (!u.existsInDatabase) {
        console.log(`    ä¸å­˜åœ¨äºæ•°æ®åº“`)
      }
      if (u.httpStatus && u.httpStatus >= 400) {
        console.log(`    HTTP ${u.httpStatus}`)
      }
    })
    if (problemURLs.length > 10) {
      console.log(`  ... è¿˜æœ‰ ${problemURLs.length - 10} ä¸ªé—®é¢˜ URL`)
    }
  }

  // å¯¼å‡º CSV
  if (exportCsv) {
    const reportPath = 'sitemap-http-validation-report.csv'
    const csvHeaders = ['URL', 'Sitemap', 'ç±»å‹', 'Slug', 'å­˜åœ¨äºæ•°æ®åº“', 'å·²å‘å¸ƒ', 'HTTPçŠ¶æ€', 'HTTPé”™è¯¯', 'æ•°æ®åº“ID']
    const csvRows = allURLs.map((u) => [
      u.url,
      u.sitemap,
      u.type,
      u.slug || '',
      u.existsInDatabase ? 'æ˜¯' : 'å¦',
      u.published ? 'æ˜¯' : 'å¦',
      u.httpStatus?.toString() || '',
      u.httpError || '',
      u.databaseId?.toString() || '',
    ])

    const csv = [
      csvHeaders.join(','),
      ...csvRows.map((row) => row.map((cell) => `"${String(cell).replace(/"/g, '""')}"`).join(',')),
    ].join('\n')

    writeFileSync(reportPath, csv, 'utf-8')
    console.log(`\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: ${reportPath}`)
  }

  console.log('\nâœ… éªŒè¯å®Œæˆ!')
}

main().catch((error) => {
  console.error('âŒ è‡´å‘½é”™è¯¯:', error)
  process.exit(1)
})
