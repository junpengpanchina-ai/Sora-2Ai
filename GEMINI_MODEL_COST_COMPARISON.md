# Gemini 模型成本对比表

## 📊 完整成本对比（每百万 tokens）

| 模型 | 输入成本 | 输出成本 | 联网搜索 | 最大Token | 速度 | 适用场景 |
|------|---------|---------|---------|-----------|------|---------|
| **gemini-2.5-flash** | ￥***~*** /M | ￥***~*** /M | ❌ 不支持 | 1,048,576 | ⚡ 最快 | 快速生成，成本敏感 |
| **gemini-3-flash** | ￥***~*** /M | ￥***~*** /M | ✅ **支持** | - | ⚡ 快 | 需要联网搜索，平衡成本 |
| **gemini-3-pro** | ￥***~*** /M | ￥***~*** /M | ✅ 支持 | - | 🐢 较慢 | 复杂任务，最高质量 |

## 💰 人民币成本对比（实际价格）

| 模型 | 输入成本 | 输出成本 | 联网搜索 | 总成本（输入+输出） | 成本倍数 |
|------|---------|---------|---------|------------------|---------|
| **gemini-2.5-flash** | ￥***~*** /M | ￥***~*** /M | ❌ | **￥***~*** /M** | 1x |
| **gemini-3-flash** | ￥***~*** /M | ￥***~*** /M | ✅ | **￥***~*** /M** | **2~2.5x** |
| **gemini-3-pro** | ￥***~*** /M | ￥***~*** /M | ✅ | **￥***~*** /M** | 8~15x |

## 📈 实际使用成本估算

### 场景：批量生成 10,000 条场景词（100 个行业 × 100 条/行业）

假设每次 API 调用：
- **输入 tokens**: 约 2,000 tokens（提示词 + 系统提示）
- **输出 tokens**: 约 15,000 tokens（100 条场景词，每条约 150 tokens）

**100 次 API 调用总计：**
- 输入：200,000 tokens = 0.2M tokens
- 输出：1,500,000 tokens = 1.5M tokens

#### 成本计算（使用实际价格）：

| 模型 | 输入成本 | 输出成本 | **总成本** | 成本倍数 |
|------|---------|---------|-----------|---------|
| **gemini-2.5-flash** | ￥***~*** | ￥***~*** | **￥***~***** | 1x |
| **gemini-3-flash** | ￥***~*** | ￥***~*** | **￥***~***** | **2.4~2.5x** |
| **gemini-3-pro** | ￥***~*** | ￥***~*** | **￥***~***** | 9.6~10x |

## 🎯 推荐选择

### 1. **gemini-2.5-flash**（当前默认）
- ✅ **最低成本**：￥***~*** / 10,000 条
- ✅ **最快速度**
- ✅ **最大Token支持**：1,048,576 tokens
- ❌ 不支持联网搜索
- **适用**：标准场景词生成，不需要实时信息

### 2. **gemini-3-flash**（推荐升级）
- ✅ **支持联网搜索**：可获取最新行业趋势
- ✅ **成本适中**：￥***~*** / 10,000 条（约 **2.4~2.5倍**成本）
- ✅ **速度快**
- ✅ **输入成本更低**：￥***~*** /M（比 2.5-flash 更便宜）
- **适用**：需要最新行业信息的场景词生成

### 3. **gemini-3-pro**
- ✅ **最高质量**：更强的推理能力
- ✅ **支持联网搜索**
- ❌ **成本最高**：￥***~*** / 10,000 条（约 **10倍**成本）
- ❌ **速度较慢**
- **适用**：复杂任务，对质量要求极高

## ⚙️ 如何配置

### 在 Vercel 环境变量中设置：

#### 选项 1：使用 gemini-3-flash（推荐）
```bash
BATCH_GENERATION_MODEL=gemini-3-flash
ENABLE_WEB_SEARCH=true
```

#### 选项 2：使用 gemini-3-pro（最高质量）
```bash
BATCH_GENERATION_MODEL=gemini-3-pro
ENABLE_WEB_SEARCH=true
```

#### 选项 3：保持 gemini-2.5-flash（最低成本）
```bash
# 不设置或设置为
BATCH_GENERATION_MODEL=gemini-2.5-flash
# ENABLE_WEB_SEARCH 无效（模型不支持）
```

## 📝 注意事项

1. **联网搜索会增加响应时间**：每次搜索需要额外时间
2. **成本会随输出增加**：输出 tokens 越多，成本越高
3. **建议先小规模测试**：确认效果后再大规模使用
4. **监控成本**：定期检查 API 使用量和成本

## 🔄 成本优化建议

1. **批量生成时**：使用 `gemini-2.5-flash` 降低成本
2. **需要最新信息时**：使用 `gemini-3-flash` 启用联网搜索
3. **复杂任务时**：使用 `gemini-3-pro` 获得最高质量
4. **混合策略**：根据任务类型动态选择模型

